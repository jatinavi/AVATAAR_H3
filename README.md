# **Scene Composition with Object Segmentation and Position Shifting**

## **Overview**
This project demonstrates how to perform scene composition using **pre-trained segmentation models** to identify objects in an image and change their positions as specified by user input. The tasks include:
1. **Object Segmentation**: Identifying objects in an image based on a class prompt and overlaying a red mask on the segmented object.
2. **Object Shifting**: Moving the segmented object within the same image by shifting it horizontally and/or vertically based on user-defined pixel shifts.

This project leverages **SAM (Segment Anything Model)** for object segmentation, allowing post-production editing of images, such as product photos for e-commerce.

---

## **Table of Contents**
- [Overview](#overview)
- [Installation](#installation)
- [How to Run the Project](#how-to-run-the-project)
- [Examples](#examples)
- [Project Structure](#project-structure)
- [Results](#results)
- [Future Enhancements](#future-enhancements)
- [References](#references)

---

## **Installation**

### **1. Clone the Repository**
First, clone the GitHub repository:

```bash
git clone https://github.com/your-username/scene-composition-project.git
cd scene-composition-project
```

### **2. Install Dependencies**
The project requires several dependencies, such as `transformers`, `Pillow`, and `numpy`. You can install them using `pip`:

```bash
pip install -r requirements.txt
```

Alternatively, manually install the dependencies:

```bash
pip install transformers Pillow numpy
```

### **3. (Optional) Use Google Colab**
If you want to run the project in Google Colab (for free GPU access), simply open the Colab notebook, and all required packages will be installed automatically:

```python
!pip install transformers Pillow numpy
```

---

## **How to Run the Project**

### **1. Object Segmentation (Task 1)**

Run the object segmentation task to detect an object in an image based on a class prompt. This will create an output image with the segmented object highlighted with a red mask.

#### Example Command:
```bash
python run.py --image ./images/example.jpg --class "shelf" --output ./output_images/segmented_output.png
```

### **2. Object Position Shifting (Task 2)**

This task allows you to shift the position of the segmented object within the image based on user input for x and y pixel shifts.

#### Example Command:
```bash
python run.py --image ./images/example.jpg --class "shelf" --x 80 --y 50 --output ./output_images/shifted_output.png
```

### **Using Google Colab**:
- Upload the required images using the `files.upload()` method or mount Google Drive to access your images.
- Use the same commands in Colab to run the segmentation and object shifting tasks.

---

## **Examples**

### **Example 1: Segmenting a Shelf**
#### Input:
![Input Image](./images/example.jpg)
#### Command:
```bash
python run.py --image ./images/example.jpg --class "shelf" --output ./output_images/segmented_output.png
```
#### Output:
![Output Image](./output_images/segmented_output.png)

---

### **Example 2: Shifting the Shelf**
#### Command:
```bash
python run.py --image ./images/example.jpg --class "shelf" --x 100 --y 50 --output ./output_images/shifted_output.png
```
#### Output:
![Shifted Output](./output_images/shifted_output.png)

---

## **Project Structure**

```
.
├── images                    # Input images for segmentation
│   ├── example.jpg
│   └── ...                   
├── output_images             # Output images generated by the tasks
│   ├── segmented_output.png
│   ├── shifted_output.png
│   └── ...
├── run.py                    # Main Python script to run both tasks
├── requirements.txt          # Dependencies required for the project
├── README.md                 # Documentation (this file)
└── ...
```

---

## **Results**

### **Task 1: Object Segmentation**
The segmentation task was successful in identifying objects based on user-provided class prompts. We used SAM (Segment Anything Model) to perform segmentation and added a red mask to highlight the objects.

**Challenges**:
- Objects with complex textures and lighting posed minor issues in generating accurate segmentation masks.

### **Task 2: Object Shifting**
The shifting task demonstrated the ability to move segmented objects within the image. The process was smooth for simple, well-isolated objects but had challenges when the background was more complex or when objects overlapped.

**Challenges**:
- While the model successfully shifted objects, in some cases, overlapping objects resulted in artifacts.

### **Performance**
- **Segmentation Time**: The SAM model segmented most objects within a few seconds, even on CPU.
- **Shifting Accuracy**: Objects were shifted with pixel-perfect accuracy based on the provided x and y values.

---

## **Future Enhancements**

Here are some potential future improvements to make the project more robust and user-friendly:
1. **User Interface (UI)**: Implement a web-based UI using **Gradio** or **Streamlit** where users can upload images, specify objects, and interactively shift the objects.
2. **Fine-Tuning**: Fine-tune the segmentation model for specific use cases to improve accuracy, particularly for complex scenes.
3. **Image Preprocessing**: Enhance image preprocessing techniques (e.g., edge detection) to improve segmentation quality in cases with complex backgrounds.
4. **Advanced Shifting Logic**: Implement more advanced shifting techniques that account for object context, avoiding overlapping with other scene objects.

---

## **References**

1. [SAM - Segment Anything Model](https://segment-anything.com/)
2. [Hugging Face Transformers](https://huggingface.co/transformers/)
3. [RunwayML Stable Diffusion Inpainting](https://huggingface.co/runwayml/stable-diffusion-inpainting)
4. [Stable Diffusion Inpainting](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting)

---

## **Conclusion**
This project demonstrates the power of using pre-trained models for object segmentation and manipulation in post-production workflows. It can be applied to various real-world scenarios such as product photography for e-commerce or creative media editing.

Feel free to contribute or open an issue if you have any questions or suggestions!

---
